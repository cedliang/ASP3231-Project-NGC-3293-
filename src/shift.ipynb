{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling - Cedric Liang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Selection\n",
    "\n",
    "Now that our science images have been processed according to the procedure described in the opening chapters of Rieke, we must process the images further to remove problematic systemic issues in our data.\n",
    "\n",
    "A great deal of our images were taken in imperfect conditions without the usage of the auto-tracker. As such, there is noticeable movement of the open cluster in our images, and we must computationally correct for these imperfections.\n",
    "\n",
    "However, it first makes sense to get a statistical overview of the images and use some common sense to discard the ones that are clearly unfit for use. There was intermittent cloud cover on the night of our observations, and as such a reasonable portion (30-40%) of the images were taken such that the background was significantly elevated due to the reflection of terrestrial light - in some cases up to 20,000 counts.\n",
    "\n",
    "As such, it makes sense for us to first analyse our data and determine which images to simply discard.\n",
    "\n",
    "There is also a human element to this - it is more difficult for computational methods to discard qualitatively poor images that can impact our results, such as images with poor focus or streaking. Indeed, we noticed on the night of observation that some images had trails. With the quantity of data that we have, it makes more sense to discard these manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import ccdproc\n",
    "from ccdproc import CCDData\n",
    "from photutils.centroids import centroid_2dg\n",
    "from scipy.ndimage import shift\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "ROOT_PATH = os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
    "\n",
    "# key values for our bands\n",
    "BANDS = [\"V\", \"B\", \"R\"]\n",
    "\n",
    "# redefining functions since importing across notebooks seems to be unreliable\n",
    "\n",
    "\n",
    "def image_stats(image):\n",
    "    return {\n",
    "        'Min': np.min(image),\n",
    "        'Max': np.max(image),\n",
    "        'Mean': np.mean(image),\n",
    "        'Mdn': np.median(image),\n",
    "        'Stdev': np.std(image)\n",
    "    }\n",
    "\n",
    "\n",
    "def print_stats(label: str, stats_dict):\n",
    "    print(\"\\n\", label)\n",
    "    for key, value in stats_dict.items():\n",
    "        print(\"\\t\", key, \"\\t\\t\", value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Nico]** I started with the V-band and viewed the images in ds9 to visually inspect these images for tracking and focussing errors.\n",
    "\n",
    "V-band images:\n",
    "Looks good: 3862-3871, 3922, 3923, 3925, 3926, 3927, 4052, 4062, 4064, 4098, 4099\\\n",
    "Slight tracking errors: 3929, 4053, 4063\\\n",
    "Big tracking errors: 3920, 3921, 3924, 3928, 4065\\\n",
    "Lots of cloud: 4058, 4059\n",
    "\n",
    "Then I looked at the B-band:\n",
    "\n",
    "Looks good: 3852-3861, 3882, 3885, 3886, 3889, 3890, 3942, 3943, 3946, 3947, 3950, 3951\\\n",
    "Slight focusing errors: 3816-3825\\\n",
    "Slight tracking errors: 3816, 3883, 3887, 3891, 3944, 3948\\\n",
    "Big tracking errors: 3884, 3888, 3945, 3949"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Cedric from here onwards]** Selecting R-band images - we filter based on qualitative suitability, with a preference for filtering out the images with severe streaking. We can filter the cloud cover images statistically/computationally later on, but a lack of focus/streaking is harder to do.\n",
    "\n",
    "- üòÅ Great : 3872-3881, 4056, \n",
    "- ü§® Okay: 4094, 4095, 3937, 3933, 4057, \n",
    "- üòû Use if must: 3930, 4060, \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image 4056 here has a relatively elevated background count, but it seems to be the sharpest/the one most in focus and with the least tracking issues. As such, it seems to be the most suitable for shifting as the centroid calculation would be the most reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we have a reference star. Let's go through the process of shifting based on this star."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image numbers that are acceptable for each band\n",
    "\n",
    "good_images = {\n",
    "    \"B\": list(range(3852, 3862)) + [3885, 3886, 3889, 3890, 3942, 3943, 3946, 3947, 3950, 3951],\n",
    "    \"V\": list(range(3862, 3872)) + [3922, 3923] + list(range(3925, 3928)) + [4052, 4062, 4064, 4098, 4099],\n",
    "    \"R\": list(range(3872, 3882)) + [3933, 3937, 4056, 4057, 4094, 4095]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 16\n"
     ]
    }
   ],
   "source": [
    "proc_files = {band: ccdproc.ImageFileCollection(\n",
    "    f\"{ROOT_PATH}/src/processed_ims/\", glob_include=f\"proc_NGC_3293_{band}*\") for band in BANDS}\n",
    "\n",
    "# idx: 20:24 represents the four digits in the file names that represent the file number\n",
    "# here we're reading only the files that we have selected\n",
    "scim = {\n",
    "    band: [CCDData.read(f\"{ROOT_PATH}/src/processed_ims/{fn}\")\n",
    "           for fn in image_files.files_filtered(PICTTYPE=1)\n",
    "           if int(fn[20:24]) in good_images[band]]\n",
    "    for band, image_files\n",
    "    in proc_files.items()}\n",
    "\n",
    "# number of images we have for each band\n",
    "print(len(scim[\"V\"]), len(scim[\"B\"]), len(scim[\"R\"]))\n",
    "# print(new_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also copy these selected images to a new directory so that if we need to access them with ds9, we don't have to go sorting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "with contextlib.suppress(OSError):\n",
    "    os.mkdir(f\"{ROOT_PATH}/src/processed_ims/selected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "temp_names = {band: [fn for fn in image_files.files_filtered(PICTTYPE=1) if int(\n",
    "    fn[20:24]) in good_images[band]] for band, image_files in proc_files.items()}\n",
    "\n",
    "for band, files in temp_names.items():\n",
    "    for filename in files:\n",
    "        shutil.copyfile(f\"{ROOT_PATH}/src/processed_ims/{filename}\",\n",
    "                        f\"{ROOT_PATH}/src/processed_ims/selected/{filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now shift these images. Unfortunately, we have a huge amount of tracking error/object relative displacement throughout the night, and after viewing the images in ds9, it becomes apparent that it's impossible to define a single shift for these images since the extremes of the locations of some of the objects across the objects exceeds the size of any region in which there is a single star and not much else.\n",
    "\n",
    "As such, we will have to perform shifting in two stages - the first is to group 'similarly positioned' objects and shift them within the group (relative to each other), then the next step will be to perform a global shift using the displacements for each group to produce a globally shifted image. \n",
    "\n",
    "Well - we'll see what we get after the first stage shifts - it could be the case that we need a few iterative stages of shifting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I manually went through ds9 and grouped the stars into the following groups, along with the boxes defined that contain a single star within them for each group, and as such can be used for an offset.\n",
    "\n",
    "\n",
    "**B band**\n",
    "- Group 0: [3852-3861]: (437-485, 1171-1204)\n",
    "- Group 1: [3885-3886, 3889-3890]: (1194-1258, 1081-1141)\n",
    "- Group 2: [3942-3943, 3946-3947]: (1296-1350, 1001-1066)\n",
    "- Group 3: [3950-3951]: (440-465, 1197-1232)\n",
    "\n",
    "**R band**\n",
    "- Group 4: [3872-3881]: (1266-1309, 1046-1082)\n",
    "- Group 5: [3933, 3937]: (746-789, 1102-1151)\n",
    "- Group 6: [4056-4057, 4094-4095]: (1335-1373, 987-1035) - Note that 4056 is the intended global reference star, so ensure that all objects in this group are also shifted relative to 4056\n",
    "\n",
    "**V band**\n",
    "- Group 7: [3862-3871]: (1613-1657, 403-454)\n",
    "- Group 8: [3922-3923, 3925-3926, 4098-4099]: (1292-1354, 998-1059)\n",
    "- Group 9: [4052]\n",
    "- Group 10 [4062, 4064]: (19-100, 791-874)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define groups\n",
    "# index is group number\n",
    "# zeroeth index is list of image numbers\n",
    "# first index is tuple of coords\n",
    "groups = [\n",
    "    (list(range(3852, 3862)), (437, 485), (1171, 1204)),\n",
    "    ([3885, 3886, 3889, 3890], (1194, 1258), (1081, 1141)),\n",
    "    ([3942, 3943, 3946, 3947], (1299, 1348), (1001, 1062)),\n",
    "    ([3950, 3951], (440, 465), (1197, 1232)),\n",
    "\n",
    "    (list(range(3872, 3882)), (1266, 1309), (1046, 1082)),\n",
    "    ([3933, 3937], (670, 720), (35, 88)),\n",
    "    ([4056, 4057, 4094, 4095], (1335, 1373), (987, 1035)),\n",
    "\n",
    "    (list(range(3862, 3872)), (1613, 1657), (403, 454)),\n",
    "    ([3922, 3923, 3925, 3926, 4098, 4099], (1292, 1354), (998, 1059)),\n",
    "    ([4052], (100, 200), (100, 200)),\n",
    "    ([4062, 4064], (952, 981), (279, 322))\n",
    "]\n",
    "\n",
    "local_image_files = ccdproc.ImageFileCollection(\n",
    "    f\"{ROOT_PATH}/src/processed_ims/\", glob_include=f\"proc_NGC_3293_*\")\n",
    "\n",
    "scim_groups = []\n",
    "for group in groups:\n",
    "    group_image_numbers = group[0]\n",
    "\n",
    "    group_scims = [CCDData.read(f\"{ROOT_PATH}/src/processed_ims/{fn}\")\n",
    "                   for fn in local_image_files.files_filtered(PICTTYPE=1)\n",
    "                   if int(fn[20:24]) in group_image_numbers]\n",
    "\n",
    "    scim_groups.append(group_scims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0: [(0, 0), (0, 0), (2, 0), (0, 0), (3, -1), (7, -2), (8, -2), (11, -3), (11, -3), (15, -5)]\n",
      "Group 1: [(0, 0), (2, -6), (29, -24), (26, -28)]\n",
      "Group 2: [(0, 0), (2, -7), (21, -28), (22, -35)]\n",
      "Group 3: [(0, 0), (3, -9)]\n",
      "Group 4: [(0, 0), (2, -2), (4, -2), (5, -3), (7, -5), (8, -6), (11, -7), (12, -8), (14, -9), (17, -8)]\n",
      "Group 5: [(0, 0), (24, -26)]\n",
      "Group 6: [(0, 0), (2, -7), (2, -3), (5, -10)]\n",
      "Group 7: [(0, 0), (0, 0), (1, -1), (0, -2), (0, -3), (0, -3), (0, -4), (1, -5), (1, -5), (1, -6)]\n",
      "Group 8: [(0, 0), (-1, -3), (21, -18), (29, -26), (2, -33), (6, -34)]\n",
      "Group 9: [(0, 0)]\n",
      "Group 10: [(0, 0), (4, -15)]\n"
     ]
    }
   ],
   "source": [
    "shifts = []\n",
    "\n",
    "for idx in range(len(groups)):\n",
    "    group_scim = scim_groups[idx]\n",
    "    x_range = groups[idx][1]\n",
    "    y_range = groups[idx][2]\n",
    "\n",
    "    xoffset = x_range[0]\n",
    "    yoffset = y_range[0]\n",
    "    xbox = x_range[1] - xoffset\n",
    "    ybox = y_range[1] - yoffset\n",
    "\n",
    "    shiftx = []\n",
    "    shifty = []\n",
    "\n",
    "    for local_image in group_scim:\n",
    "        temp = local_image.copy()\n",
    "        temp = temp-np.ma.median(temp)\n",
    "        x1, y1 = centroid_2dg(\n",
    "            temp[yoffset: yoffset + ybox, xoffset: xoffset + xbox])\n",
    "\n",
    "        shiftx.append(x1 + xoffset)\n",
    "        shifty.append(y1 + yoffset)\n",
    "\n",
    "    # shift relative to the first image in each group - to ensure that 4056 is used as the reference for its group.\n",
    "    shifts_zipped = list(map(lambda tup: (round(tup[0]), round(\n",
    "        tup[1])), zip(shiftx[0]-shiftx, shifty[0]-shifty)))\n",
    "    shifts.append(shifts_zipped)\n",
    "\n",
    "for idx, sft in enumerate(shifts):\n",
    "    print(f\"Group {idx}: {sft}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now perform our shifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file_names = {int(fn[20:24]): fn\n",
    "                  for fn in local_image_files.files\n",
    "                  }\n",
    "\n",
    "# uncomment this if you need to see intermediary files - but I've commented it to save space\n",
    "# with contextlib.suppress(OSError):\n",
    "#     os.mkdir(f\"{ROOT_PATH}/src/shift_stage1/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_stage_shifted = []\n",
    "\n",
    "for idx in range(len(groups)):\n",
    "    group_scim = scim_groups[idx]\n",
    "    group_shifted = []\n",
    "    for image_idx, local_image in enumerate(group_scim):\n",
    "        # Note the y-x convention being used here and in the following command.\n",
    "        yxshifts = (shifts[idx][image_idx][1], shifts[idx][image_idx][0])\n",
    "\n",
    "        temp = CCDData(shift(local_image, yxshifts, order=0, mode='constant',\n",
    "                       cval=-1000)-np.ma.median(local_image), unit=\"adu\")\n",
    "        temp.header = local_image.header\n",
    "        group_shifted.append(temp)\n",
    "        new_file_name = \"s1\" + new_file_names[groups[idx][0][image_idx]]\n",
    "        new_file_dir = f\"{ROOT_PATH}/src/shift_stage1/\"\n",
    "\n",
    "        # uncomment this if you need to see intermediary files - but I've commented it to save space\n",
    "        # temp.write(new_file_dir + new_file_name, overwrite=True)\n",
    "    first_stage_shifted.append(group_shifted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have performed our first stage shift - let's take a look at them in ds9. We should expect to see images in the same group have little translation relative to each other.\n",
    "\n",
    "We find that images within a group are shifted - not perfectly, since the size of the boxes we defined and the magnitude of the translation we needed to account for potentially introduced some issues with regards to centroid calculation - perhaps the 'corona' of another object is within our boxes, causing the shifts to be a pixel or two off sometimes.\n",
    "\n",
    "That's not an issue though - we'll perform a final shift later on once we've aligned the groups in order to get rid of this small scale error. We'll now correct for the large scale error manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll select a distinct star in our reference image 4056 - bright enough to be distinguised in all all our images, but faint enough so that it doesn't illuminate too many pixels, which would reduce the 'precision' of our manual eyeball shift. I'll select the star at 681, 409 in that image.\n",
    "\n",
    "Now, we'll go through each group and manually list the approximate coordinates of that star in that group. That will define the offset from 681, 409 that will be applied to the entire group.\n",
    "\n",
    "Group 0: (631, 448)\\\n",
    "Group 1: (564, 499)\\\n",
    "Group 2: (658, 417)\\\n",
    "Group 3: (618, 470)\n",
    "\n",
    "Group 4: (615, 464)\\\n",
    "Group 5: (590, 490)\\\n",
    "Group 6: (681, 409) - REFERENCE\n",
    "\n",
    "Group 7: (612, 456)\\\n",
    "Group 8: (658, 416)\\\n",
    "Group 9: (575, 524)\\\n",
    "Group 10: (634, 466)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(50, -39), (117, -90), (23, -8), (63, -61), (66, -55), (91, -81), (0, 0), (69, -47), (23, -7), (106, -115), (47, -57)]\n"
     ]
    }
   ],
   "source": [
    "# offset for each\n",
    "location_ref = (681, 409)\n",
    "\n",
    "actual_loc = [\n",
    "    (631, 448),\n",
    "    (564, 499),\n",
    "    (658, 417),\n",
    "    (618, 470),\n",
    "    (615, 464),\n",
    "    (590, 490),\n",
    "    (681, 409),\n",
    "    (612, 456),\n",
    "    (658, 416),\n",
    "    (575, 524),\n",
    "    (634, 466)\n",
    "]\n",
    "\n",
    "group_offsets = [\n",
    "    (-1*(tup[0]-location_ref[0]), -1*(tup[1]-location_ref[1]))\n",
    "    for tup in actual_loc\n",
    "]\n",
    "\n",
    "print(group_offsets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the offset for each group, we can perform the shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this if you need to see intermediary files - but I've commented it to save space\n",
    "# with contextlib.suppress(OSError):\n",
    "#     os.mkdir(f\"{ROOT_PATH}/src/shift_stage2/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_stage_shifted = []\n",
    "\n",
    "for idx in range(len(groups)):\n",
    "    group_scim = first_stage_shifted[idx]\n",
    "    group_shifted = []\n",
    "    for image_idx, local_image in enumerate(group_scim):\n",
    "        # Note the y-x convention being used here and in the following command.\n",
    "        yxshifts = (group_offsets[idx][1], group_offsets[idx][0])\n",
    "\n",
    "        temp = CCDData(shift(local_image, yxshifts, order=0,\n",
    "                       mode='constant', cval=-1000), unit=\"adu\")\n",
    "        temp.header = local_image.header\n",
    "        group_shifted.append(temp)\n",
    "        new_file_name = \"s2\" + new_file_names[groups[idx][0][image_idx]]\n",
    "        new_file_dir = f\"{ROOT_PATH}/src/shift_stage2/\"\n",
    "\n",
    "        # uncomment this if you need to see intermediary files - but I've commented it to save space\n",
    "        # temp.write(new_file_dir + new_file_name, overwrite=True)\n",
    "\n",
    "    second_stage_shifted.append(group_shifted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspection with DS9 shows that the large scale errors are no longer there. We'll shift one more time to get rid of the small scale issues we noticed before - it's much easier now since we can flatten the group and choose a single star that's present in all the images, as well as use a relatively small box.\n",
    "\n",
    "We'll use the box\n",
    "    (902-942, 488-527)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0: [(0, 0), (1, 0), (0, -1), (3, -2), (2, -1), (0, 0), (0, 0), (-1, 0), (0, 0), (-3, 1)]\n",
      "Group 1: [(0, 0), (1, 0), (-4, 2), (1, 0)]\n",
      "Group 2: [(0, -1), (-1, -1), (-1, -1), (-1, -1)]\n",
      "Group 3: [(-1, -2), (-1, -2)]\n",
      "Group 4: [(1, -4), (0, -2), (-1, -3), (-1, -2), (-2, -1), (-2, 0), (-4, 0), (-4, 1), (-5, 1), (-6, 0)]\n",
      "Group 5: [(-1, 0), (-1, -1)]\n",
      "Group 6: [(0, -2), (-1, 0), (-2, -1), (-2, -1)]\n",
      "Group 7: [(1, -1), (2, -2), (1, -1), (2, -1), (2, -1), (2, -2), (2, -1), (2, -1), (2, -2), (2, -2)]\n",
      "Group 8: [(-1, -1), (3, -4), (-1, -1), (-5, 2), (2, 6), (-1, 0)]\n",
      "Group 9: [(-1, -2)]\n",
      "Group 10: [(-1, -2), (-1, -2)]\n"
     ]
    }
   ],
   "source": [
    "xoffset = 902\n",
    "yoffset = 488\n",
    "xbox = 942 - xoffset\n",
    "ybox = 527 - yoffset\n",
    "\n",
    "reference_x = None\n",
    "reference_y = None\n",
    "shifts_final = []\n",
    "\n",
    "for idx in range(len(groups)):\n",
    "    group_scim = second_stage_shifted[idx]\n",
    "\n",
    "    shiftx = []\n",
    "    shifty = []\n",
    "\n",
    "    for local_image in group_scim:\n",
    "        temp = local_image.copy()\n",
    "        temp = temp-np.ma.median(temp)\n",
    "        x1, y1 = centroid_2dg(\n",
    "            temp[yoffset: yoffset + ybox, xoffset: xoffset + xbox])\n",
    "\n",
    "        shiftx.append(x1 + xoffset)\n",
    "        shifty.append(y1 + yoffset)\n",
    "\n",
    "    # now we only want to refer to the first image out of all of them, not the first image in each group\n",
    "    reference_x = shiftx[0] if not reference_x else reference_x\n",
    "    reference_y = shifty[0] if not reference_y else reference_y\n",
    "\n",
    "    shifts_zipped = list(map(lambda tup: (round(tup[0]), round(\n",
    "        tup[1])), zip(reference_x-shiftx, reference_y-shifty)))\n",
    "    shifts_final.append(shifts_zipped)\n",
    "\n",
    "for idx, sft in enumerate(shifts_final):\n",
    "    print(f\"Group {idx}: {sft}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with contextlib.suppress(OSError):\n",
    "    os.mkdir(f\"{ROOT_PATH}/src/shift_final/\")\n",
    "\n",
    "for idx in range(len(groups)):\n",
    "    group_scim = second_stage_shifted[idx]\n",
    "    for image_idx, local_image in enumerate(group_scim):\n",
    "        # Note the y-x convention being used here and in the following command.\n",
    "        yxshifts = (shifts_final[idx][image_idx][1],\n",
    "                    shifts_final[idx][image_idx][0])\n",
    "\n",
    "        temp = CCDData(shift(local_image, yxshifts, order=0,\n",
    "                       mode='constant', cval=-1000), unit=\"adu\")\n",
    "        temp.header = local_image.header\n",
    "        new_file_name = \"s\" + new_file_names[groups[idx][0][image_idx]]\n",
    "        new_file_dir = f\"{ROOT_PATH}/src/shift_final/\"\n",
    "\n",
    "        temp.write(new_file_dir + new_file_name, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our shifts in ds9 - they look good! Little to no translation in ds9, which means our shifts have been successful and our images are ready to be combined."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8df94411eb56358a74dbf903bd81fb6d2d46beab2e2199f41a79d4acff0ee653"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
